{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minstone\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from libs.SatelliteEnvironment import *\n",
    "from libs.DRLAgents.DQNAgent import *\n",
    "from libs.Constants import *\n",
    "\n",
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORBIT NUM :  2\n",
      "SAT NUM :  8\n",
      "STATE NUM :  36\n",
      "ACTION NUM :  16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\pySatellite\\DQNAgent_test_bed.ipynb Cell 2\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pySatellite/DQNAgent_test_bed.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mget_action(state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pySatellite/DQNAgent_test_bed.ipynb#W1sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/pySatellite/DQNAgent_test_bed.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m next_state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mget_state() \u001b[39m# \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pySatellite/DQNAgent_test_bed.ipynb#W1sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m agent\u001b[39m.\u001b[39mappend_sample(state\u001b[39m=\u001b[39mstate, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pySatellite/DQNAgent_test_bed.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m                     action\u001b[39m=\u001b[39maction, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pySatellite/DQNAgent_test_bed.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                     reward\u001b[39m=\u001b[39mreward, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pySatellite/DQNAgent_test_bed.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                     next_state\u001b[39m=\u001b[39mnext_state,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pySatellite/DQNAgent_test_bed.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m                     done\u001b[39m=\u001b[39mdone) \u001b[39m# \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pySatellite/DQNAgent_test_bed.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m ep_reward \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n",
      "File \u001b[1;32md:\\pySatellite\\libs\\SatelliteEnvironment.py:126\u001b[0m, in \u001b[0;36mCircularOrbit.get_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m _flatten \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([_flatten, _src_sat_flatten])\n\u001b[0;32m    125\u001b[0m _dst_sat_flatten \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdestination_satellite)\n\u001b[1;32m--> 126\u001b[0m _flatten \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate([_flatten, _dst_sat_flatten])\n\u001b[0;32m    128\u001b[0m np\u001b[39m.\u001b[39mappend(_flatten, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_time)\n\u001b[0;32m    129\u001b[0m \u001b[39m# _rest_time = np.array(self.rest_time)\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# _flatten = np.concatenate([_flatten, _rest_time])\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = CircularOrbit(\n",
    "    satellite_num=1000\n",
    ")\n",
    "\n",
    "env.reset()\n",
    "\n",
    "state = env.get_state()\n",
    "\n",
    "num_states = state.shape[0]\n",
    "orbit_num  = env.orbit_num\n",
    "sat_num    = env.satellite_num\n",
    "num_action = orbit_num * sat_num\n",
    "\n",
    "print(\"ORBIT NUM : \", orbit_num)\n",
    "print(\"SAT NUM : \", sat_num)\n",
    "print(\"STATE NUM : \", num_states)\n",
    "print(\"ACTION NUM : \", num_action)\n",
    "\n",
    "agent      = DQNAgent(num_states = num_states,\n",
    "                      num_action = num_action)\n",
    "\n",
    "agent.train()\n",
    "\n",
    "losses = []\n",
    "rewards = []\n",
    "\n",
    "episodes = 10000\n",
    "for episode in range(episodes):\n",
    "    env.reset()\n",
    "\n",
    "    ep_reward = 0\n",
    "    ep_loss = 0\n",
    "    step = 0\n",
    "    while True:\n",
    "        step += 1\n",
    "        state = env.get_state()\n",
    "\n",
    "        action = agent.get_action(state)\n",
    "\n",
    "        reward, done, info = env.step(action)\n",
    "\n",
    "        next_state = env.get_state() # \n",
    "            \n",
    "        agent.append_sample(state=state, \n",
    "                            action=action, \n",
    "                            reward=reward, \n",
    "                            next_state=next_state,\n",
    "                            done=done) # \n",
    "        \n",
    "        ep_reward += reward\n",
    "\n",
    "        if step >= MEMORY_CAPACITY:\n",
    "\n",
    "            loss = agent.train_model()\n",
    "            ep_loss += loss\n",
    "            \n",
    "            if(step % 100 == 0):\n",
    "                agent.update_target()\n",
    "            \n",
    "            if done:\n",
    "                agent.write_summary(ep_reward, ep_loss, step, episode)\n",
    "                print(\"episode: {} , the episode reward is {}\".format(step, ep_reward))\n",
    "                break\n",
    "        if done:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
